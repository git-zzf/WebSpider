[TOC]



# 网络爬虫引发的问题

## 三种网络爬虫，按尺寸划分

1. 爬取网页，玩转网页：占比90%

   小规模，数据量小，爬取速度不敏感

   Requests库来实现

2. 爬取网站，爬取系列网站

   比如获得一个旅游网站的资源，并且获得很多旅游网站的资源。 

   中规模，数据规模较大，爬取速度敏感

   爬取携程的内容，爬取速度慢的话，跟不上更新的速度

   使用Scrapy库

3. 爬取全网

   大规模，搜索引擎，爬取速度很关键

   定制开发

## 带来的问题

### 骚扰问题

服务器性能跟不上

受限于爬虫编写者的水平和目的，网络爬虫会对web服务器带来巨大的资源开销

### 法律风险

数据产权归属

爬虫如果获得数据用来牟利，就有法律风险

### 隐私泄露

爬虫可以具备突破简单访问控制的能力，获得被保护数据从而泄露个人隐私

## 网络爬虫的限制

### 来源审查：判断User-Agent进行限制

检查来访HTTP协议头的User-Agent域，只响应浏览器或友好爬虫的访问

## 发布公告：Robots协议

告诉所有爬虫网站的爬取策略，要求爬虫遵守



****

# Robots协议

Robots Exclusion Standard 网络爬虫排除标准

+ **作用**：网站告知网络爬虫哪些页面可以抓取，哪些不行

+ **形式**：在网站根目录下的robots.txt文件

## 案例：京东的Robots协议

```robots.txt
https://www.jd.com/robots.txt
User-agent: * 对于所有的网络爬虫都要遵守
Disallow: /?* 任何爬虫都不允许访问以问号开头的路径
Disallow: /pop/*.html 任何爬虫都不允许访问pop/*.html
Disallow: /pinpai/*.html?* 任何爬虫都不允许访问符合这个通配符的网页
User-agent: EtaoSpider 以下4个网络爬虫不允许爬取京东的任何资源
Disallow: / 根目录
User-agent: HuihuiSpider 
Disallow: / 
User-agent: GwdangSpider 
Disallow: / 
User-agent: WochachaSpider 
Disallow: /
```

## Robots协议基本语法

``` 
#注释，*代表所有，/代表根目录
User-agent: *
Disallow: /
```

User-agent 表明哪些爬虫，针对所有爬虫，使用*

Disallow 不允许爬虫访问的资源的目录

# 其他案例

```robots.txt
http://www.baidu.com/robots.txt
User-agent: Baiduspider
Disallow: /baidu
Disallow: /s?
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: Googlebot
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: MSNBot
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: Baiduspider-image
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: YoudaoBot
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: Sogou web spider
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: Sogou inst spider
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: Sogou spider2
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: Sogou blog
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: Sogou News Spider
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: Sogou Orion spider
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: ChinasoSpider
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: Sosospider
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh


User-agent: yisouspider
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: EasouSpider
Disallow: /baidu
Disallow: /s?
Disallow: /shifen/
Disallow: /homepage/
Disallow: /cpro
Disallow: /ulink?
Disallow: /link?
Disallow: /home/news/data/
Disallow: /bh

User-agent: *
Disallow: /
```

```robots.txt
http://news.sina.com.cn/robots.txt
User-agent: *
Disallow: /wap/
Disallow: /iframe/
Disallow: /temp/
```

```robots.txt
http://www.qq.com/robots.txt
User-agent: *
Disallow:  
Sitemap: http://www.qq.com/sitemap_index.xml
```

```robots.txt
http://news.qq.com/robots.txt
User-agent: *
Disallow:  
Sitemap: http://www.qq.com/sitemap_index.xml
Sitemap: http://news.qq.com/topic_sitemap.xml
```

```robots.txt
http://www.moe.edu.cn/robots.txt (无robots协议)
```

```robots.txt
https://www.nike.com/robots.tx (结尾有意思)
```

robots协议规定，如果一个网站不提供robots.txt文件，那就说明这个网站允许所有爬虫不限制地爬取其内容



****

# Robots协议的遵守方式

## Robots协议的使用

+ 网络爬虫：对于任何网络爬虫来说，它都应该能够自动或人工识别robots.txt文件，根据文件内容再进行内容爬取

+ 约束性：Robots协议是建议性但非约束性，网络爬虫可以不遵守，但存在法律风险

# 对于Robots协议的理解

| 访问量很小：可以遵守<br>访问量较大：建议遵守 | 非商业且偶尔：建议遵守<br>商业利益：必须遵守 | 必须遵守 |
| -------------------------------------------- | -------------------------------------------- | -------- |
| 爬取网页 玩转网页                            | 爬取网站 爬取系列网站                        | 爬取全网 |

对于只爬取几次，而且爬取行为和人类访问行为很类似的可不参考Robots协议



****

# 单元小结

## Robots协议

```robots.txt
#注释，*代表所有，/代表根目录
User-agent: *
Disallow: /
```

## 遵守Robots协议

原则上，所有的网络爬虫都应该遵守Robots协议。

但如果网络爬虫小到和人类访问行为类似，可以不遵守，不过获取的资源不可以作为商业用途。

