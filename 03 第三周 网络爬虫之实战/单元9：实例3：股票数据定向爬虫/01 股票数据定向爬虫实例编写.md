# "股票数据定向爬虫"实例编写

## 调库

```python
import requests
from bs4 import BeautifulSoup
import traceback
import re
```

****

## 获得URL页面

```python
def getHTMLText(url):
    try:
        r = requests.get(url, timeout=30)
        r.raise_for_status()
        r.encoding = r.apparent_encoding
        return r.text
    except:
        print('爬取失败')
        return ""
```

****

## 获得股票的信息列表

```python
def getStockList(lst, stockURL):
    html = getHTMLText(stockURL)
    soup = BeautifulSoup(html, 'html.parser')
    a = soup.find_all('a')
    for i in a:
        try:
            href = i.attrs['href']
            lst.append(re.findall(r'[s][hz]\d{6}', href)[0])
        except:
            continue
```

### 股票信息列表HTML页面源代码

```html

<div class="qox">
    <div class="space3">
    </div>
    <div class="quotebody">
        <div id="quotesearch">
            <div class="sltito">股票代码查询一览表：<a href="#sh">上海股票</a>&nbsp;&nbsp;&nbsp;&nbsp;<a href="#sz">深圳股票</a></div>
            <div class="sltit"><a name="sh"/>上海股票</div>

            <ul>
                <li><a target="_blank" href="http://quote.eastmoney.com/sh201000.html">R003(201000)</a></li>

                <li><a target="_blank" href="http://quote.eastmoney.com/sh201001.html">R007(201001)</a></li>

                <li><a target="_blank" href="http://quote.eastmoney.com/sh201002.html">R014(201002)</a></li>
            </ul>
        </div>
    </div>
</div>    
```

通过分析源代码，得知，我们需要的股票信息`sh20100`储存在`a`标签的`href`部分，所以先找出网页所有的`a`标签，然后对每一个`a`标签，通过正则表达式找出符合股票格式的编号（sh或sz加6位数字表示），因为有可能找不到符合条件的`a`标签，所以要用`try...except`框架

****

## 获得每一支股票的股票信息，并储存到数据结构

```python
def getStockInfo(lst, stockURL, fpath):
    for stock in lst:
        url = stockURL + stock
        print(url)
        html = getHTMLText(url)
        try:
            if html == "":
                continue
            infoDict = {}
            soup = BeautifulSoup(html, 'html.parser')
            stockInfo = soup.find('table', attrs={'class': 'quote'})
            if isinstance(stockInfo, bs4.element.Tag):
                name = stockInfo.find('a', attrs={'target': '_blank'}).parent
            else:
                continue
            name_text = name.text.split()[0]
            infoDict.update({'股票名称': name_text})
            if isinstance(stockInfo, bs4.element.Tag):
                keyList = stockInfo.find_all('tr')
            else:
                continue
            del keyList[0]

            for i in range(len(keyList)):
                data = keyList[i].find_all('td')
                key1 = unicodedata.normalize('NFKC', data[0].text.split(':')[0])
                val1 = data[0].text.split(':')[1]
                key2 = unicodedata.normalize('NFKC', data[1].text.split(':')[0])
                val2 = data[1].text.split(':')[1]
                infoDict[key1] = val1
                infoDict[key2] = val2
            with open(fpath, 'a', encoding='utf-8') as f:
                f.write(str(infoDict) + '\n')
        except:
            traceback.print_exc()
            continue
```

### 替代网站HTML页面源代码

```html
<table style="width:960px">
    <tr>
		<td id="tdquote" style="width:240px;vertical-align:top ">
            <table style=width:100% class='quote'>
                
                <tr>
                    <td>嘉实港股通A&nbsp;
                        <a href='http://quote.cfi.cn/quote_501311.html' target='_blank'>行情
                        </a>
                    </td>
                    <td>[501311]
                    </td>
                </tr>
                
                <tr>
                    <td>最　新:
                        <span style=color:rgb(255,0,0)>
                            0.90
                        </span>
                    </td>
                    <td>
                        开　盘:0.89
                    </td>
                </tr>
                
                <tr>
                    <td>涨跌幅:
                        <span style=color:rgb(255,0,0)>
                            1.81%
                        </span>
                    </td>
                    <td>涨　跌:
                        <span style=color:rgb(255,0,0)>
                            0.02
                            </td>
                </tr>
                
                <tr>
                    <td>
                        最　高:0.90
                    </td>
                    <td>
                        最　低:0.88
                    </td>
                </tr>
                
                <tr>
                    <td>
                        成交量:11万股
                    </td>
                    <td>
                            换　手:0.00%
                    </td>
                </tr>
                
            </table>
            <img src='http://quote.cfi.cn/drawprice.aspx?style=small&f=9&w=240&h=145&type=min&stockcode=501311' style='margin-top:10px;' border=0>
            <img src='http://quote.cfi.cn/drawprice.aspx?style=small&f=9&w=240&h=145&type=day&stockcode=501311' style='margin-top:10px;' border=0>
            <br/>
        </td>
    </tr>
</table>
        


```

步骤：

1. 对于股票列表中的每一个元素都进行查找

2. 修改页面链接，定位到对应的股票

3. 用getHTMLText找到页面源代码

4. 进行判断，如果页面是空的，就跳过这次循环

5. 采用字典的数据结构储存信息

6. 用BeautifulSoup解析网页，分析标签：

   + 通过分析，发现要找的信息都存在`<table style=width:100% class='quote'>`标签下面，所以先找到这个标签。
+ 股票名称`嘉实港股通A`储存在标签`<td>`下，不过标签`<td>`有很多个，不好定位，所以通过标签`<a href='http://quote.cfi.cn/quote_501311.html' target='_blank'>`的父级标签来定位。当然，也可能`<table>`标签不存在，所以需要用`isinstance()`函数来判断是否存在`<table>`标签。
   + 用`split()`函数分离出股票名称：`嘉实港股通A&nbsp`后面的`&nbsp`表示空格，所以直接用`split()`分离出名称。并把名称储存到字典中，使用`update()`函数可以把另一个键值对添加到一个字典中。
+ 找到所有其它的信息，这些信息储存在`tr`标签下的`td`标签中，通过`find_all()`函数找出所有的`tr`标签，同理，`<table>`标签可能不存在，所以要用`isinstance()`函数判断
   + 删除`find_all()`函数返回的列表中的第一个元素，即股票名称，保留剩余信息
+ 列表中储存的是`tr`标签，共有4个，每个`tr`标签包含两个`td`标签，`td`标签包含股票信息。所以对每个`tr`标签，需要用`find_aLL()`函数找出里面的`td`标签，存储于`data`列表中
   + 对每个`td`标签里的文本信息，通过`split()`函数分开冒号前后的部分，取出第一个部分存为键，第二部分存为值。
+ 这里需要加一个库，来消除`\xa0`和`u3000`字符，这里`\xa0`表示不间断空白符。有几种办法消除，参考`https://www.jianshu.com/p/56d4babcc555`的办法，使用`unicodedata`模块，来消除这些空白符。
   + 通过`dict[key]=value`来向字典中添加元素

7. 用`open()`函数写入文件
8. 整个BeautifulSoup分析过程都需要放在`try...except`框架中，防止程序报错退出
9. 使用`traceback()`函数，可以找到报错的原因，便于排查

****

## 主函数

```python
def main():
    stock_list_url = 'http://quote.eastmoney.com/stock_list.html'
    stock_info_url = 'http://so.cfi.cn/so.aspx?txquery='
    output_file = 'E://Notes/WebSpider/03 第三周 网络爬虫之实战/单元9：实例3：股票数据定向爬虫/BaiduStockInfo.txt'

```

`output_file`路径开头要双斜杠，结尾必须加上文件名和后缀，不然无法储存