# requests库和Scrapy爬虫的比较

相同点

+ 两者都可以进行页面请求和爬取，Python爬虫的两个重要技术路线
+ 两者可用性都好，文档丰富，入门简单
+ 两者都没有处理JavaScript、提交表单、应对验证码等（需要拓展额外的库）

不同点

| requests                 | Scrapy                                                       |
| ------------------------ | ------------------------------------------------------------ |
| 页面级爬虫               | 网站级爬虫                                                   |
| 功能库                   | 框架                                                         |
| 并发性考虑不足，性能较差 | 并发性好，性能较高 <br>（基于异步结构设计，可以同时向多个网站发起爬取请求） |
| 重点在于页面下载         | 重点在于爬虫结构                                             |
| 定制灵活                 | 一般定制灵活，深度定制困难                                   |
| 上手十分简单             | 入门稍难                                                     |

对于一部分带有反爬功能的网站来说，爬取速度不能太快，不然IP会被屏蔽，所以爬取性能只是一个参数，不是越快越好，要结合特定情况来考虑。



如何选用技术路线

+ 对于非常小的爬取请求，使用requests库
+ 对于不太小的需求，使用Scrapy框架，比如希望对一个网站不间断或持续性地爬取一个网站的信息，并且对爬取到的信息进行积累形成自己的爬取库，这种情况就可以使用Scrapy框架。
+ 对于定制程度更高的需求（不考虑规模），自搭框架，使用requests库比Scrapy库更好