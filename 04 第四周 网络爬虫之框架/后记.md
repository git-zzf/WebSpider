[TOC]

# “网络爬虫”未完待续……

## Scrapy爬虫的地位：

+ 最好的爬虫框架
+ 具备企业级专业爬虫的扩展性（7*24小时高可靠性）
+ 千万级URL爬取的管理和部署

Scrapy足以支撑一般商业服务所需的爬虫能力



## Scrapy爬虫的应用展望：

+ 普通价值：
  + 基于Linux服务器，7*24小时，稳定爬取输出
  + 商业级的部署和应用（`Scrapyd-*`）
  + 千万规模内URL爬取、内容分析和存储
+ 高阶价值：
  + 基于docker，虚拟化部署
  + 中间件扩展，增加调度和监控
  + 应对各种反爬取技术



---> 爬虫进阶课程

真实项目



****

# “网络爬虫”课程回顾和总结

## 学习路线

Requests库：自动爬取HTML页面，向网络提交相关请求

robots.txt：网络爬虫”盗亦有道“

Beautiful Soup库：解析HTML页面学习了信息提取的基本方法

正则表达式库--re库：从一个页面提取关键信息

Scrapy库：专业的网络爬虫框架



## 爬虫技术路线

1. `requests-bs4-re`
2. `scrapy`（5+2结构）



## 实例

+ 5个小例子：
  + 京东商品页面爬取
  + 亚马逊商品页面爬取：反爬技术
  + 百度/360搜索关键字提交
  + 网络图片的爬取和存储
  + IP地址归属地的自动查询
+ 4个大实例：
  + 中国大学排名定向爬虫
  + 淘宝商品比价定向爬虫
  + 股票数据定向爬虫
  + 股票数据Scrapy爬虫



## 展望

学习了两条技术路线：

+ `requests-bs4-re`
+ `scrapy`

单独靠这两条技术路线不足以处理JavaScript、表单提交等相关功能

如果想实现更多功能，可以使用`PhantomJS`库

`PhantomJS`库是一个轻量级的浏览器库，可以解析JavaScript，并且从JavaScript中获取相关数据

对于`scrapy`库的拓展，可以在`https://pypi.python.org`上看到`scrapy-*`类型的库

这些库都可以完善`scrapy`库