# “网络爬虫”课程回顾和总结

## 学习路线

Requests库：自动爬取HTML页面，向网络提交相关请求

robots.txt：网络爬虫”盗亦有道“

Beautiful Soup库：解析HTML页面学习了信息提取的基本方法

正则表达式库--re库：从一个页面提取关键信息

Scrapy库：专业的网络爬虫框架



## 爬虫技术路线

1. `requests-bs4-re`
2. `scrapy`（5+2结构）



## 实例

+ 5个小例子：
  + 京东商品页面爬取
  + 亚马逊商品页面爬取：反爬技术
  + 百度/360搜索关键字提交
  + 网络图片的爬取和存储
  + IP地址归属地的自动查询
+ 4个大实例：
  + 中国大学排名定向爬虫
  + 淘宝商品比价定向爬虫
  + 股票数据定向爬虫
  + 股票数据Scrapy爬虫



## 展望

学习了两条技术路线：

+ `requests-bs4-re`
+ `scrapy`

单独靠这两条技术路线不足以处理JavaScript、表单提交等相关功能

如果想实现更多功能，可以使用`PhantomJS`库

`PhantomJS`库是一个轻量级的浏览器库，可以解析JavaScript，并且从JavaScript中获取相关数据

对于`scrapy`库的拓展，可以在`https://pypi.python.org`上看到`scrapy-*`类型的库

这些库都可以完善`scrapy`库